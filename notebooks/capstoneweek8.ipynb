{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9737cfb7-70a3-4ef3-adcb-54d40f846d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== WEEK 8 QUERIES (COPY/PASTE INTO PORTAL) ====\n",
      "\n",
      "F1  [MINIMAL_MAXIMIN]\n",
      "  Week 8 query: 0.422868-0.002773\n",
      "\n",
      "F2  [RIDGE_LOCAL_TUNED]\n",
      "  Week 8 query: 0.724285-0.264402\n",
      "  tuned alpha: 0.0001 | LOOCV MSE: 0.765797 | tuned step: 0.008\n",
      "  best observed y: 0.606096 at x_best=0.730000-0.270000\n",
      "\n",
      "F3  [RIDGE_LOCAL_TUNED]\n",
      "  Week 8 query: 0.181867-0.354586-0.878279\n",
      "  tuned alpha: 1.0 | LOOCV MSE: 1.410726 | tuned step: 0.018\n",
      "  best observed y: -0.047393 at x_best=0.178771-0.372140-0.880781\n",
      "\n",
      "F4  [RIDGE_LOCAL_TUNED]\n",
      "  Week 8 query: 0.789610-0.268623-0.368839-0.654212\n",
      "  tuned alpha: 1.0 | LOOCV MSE: 1.613717 | tuned step: 0.009\n",
      "  best observed y: -12.699964 at x_best=0.785000-0.275000-0.370000-0.650000\n",
      "\n",
      "F5  [TRUST_REGION_BO_GP_EI]\n",
      "  Week 8 query: 0.745989-0.305287-0.849251-0.788893\n",
      "  GP kernel: 7.21**2 * Matern(length_scale=[0.244, 100, 8.16, 100], nu=2.5) + WhiteKernel(noise_level=1e-10)\n",
      "  EI xi: 1e-06 | local_sigma: 0.006 | radius: 0.018000000000000002\n",
      "  candidates kept: 49482 | best EI: 3.523894e+01\n",
      "  best observed y: 365.663282 at x_best=0.728000-0.302000-0.848000-0.782000\n",
      "\n",
      "F6  [MANUAL_CONTINUE_DIR]\n",
      "  Week 8 query: 0.235280-0.694720-0.365280-0.781200-0.437360\n",
      "\n",
      "F7  [TRUST_REGION_BO_GP_EI]\n",
      "  Week 8 query: 0.789513-0.359715-0.716440-0.416791-0.231308-0.873588\n",
      "  GP kernel: 2.22**2 * Matern(length_scale=[100, 100, 100, 0.341, 100, 100], nu=2.5) + WhiteKernel(noise_level=1e-10)\n",
      "  EI xi: 1e-06 | local_sigma: 0.005 | radius: 0.015\n",
      "  candidates kept: 59061 | best EI: 4.810118e-02\n",
      "  best observed y: 1.067902 at x_best=0.791730-0.358270-0.718270-0.431730-0.228270-0.871730\n",
      "\n",
      "F8  [RIDGE_LOCAL_TUNED]\n",
      "  Week 8 query: 0.104988-0.234988-0.354988-0.500000-0.620000-0.740000-0.860000-0.960000\n",
      "  tuned alpha: 0.0001 | LOOCV MSE: 0.017835 | tuned step: 0.008\n",
      "  best observed y: 8.753168 at x_best=0.109607-0.239607-0.359607-0.500000-0.620000-0.740000-0.860000-0.960000\n",
      "\n",
      "Done. Paste each Week 8 query string into its function field.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# ============================================================\n",
    "# WEEK 8 QUERY GENERATOR (Weeks 1â€“7 data)\n",
    "#\n",
    "# Your requested strategy:\n",
    "#   âš« F1 : Ignore / minimal (cheap space-filling)\n",
    "#   ðŸŸ¡ F2,F3,F4,F8 : Ridge regression (LOOCV alpha + local step tuning)\n",
    "#   ðŸŸ¢ F5,F7 : TRUST-REGION BO (LOCAL ONLY, very small sigma, near-zero exploration)\n",
    "#   ðŸ”µ F6 : Manual (continue last improving direction)\n",
    "#\n",
    "# Objective assumed: MAXIMISE y for each function\n",
    "# (so \"less negative\" is better for F3/F4/F6)\n",
    "# ============================================================\n",
    "\n",
    "# --- sklearn availability checks ---\n",
    "try:\n",
    "    from sklearn.linear_model import Ridge\n",
    "    SKLEARN_RIDGE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKLEARN_RIDGE_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel as C\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    SKLEARN_GP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKLEARN_GP_AVAILABLE = False\n",
    "\n",
    "# Optional: suppress sklearn GP convergence warnings (they are NOT fatal)\n",
    "if SKLEARN_GP_AVAILABLE:\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# ============================================================\n",
    "# 1) DATA: Weeks 1â€“7 (X inputs, y outputs) for F1..F8\n",
    "# ============================================================\n",
    "DATA = {\n",
    "    \"F1\": {\n",
    "        \"X\": np.array([\n",
    "            [0.145000, 0.515000],  # W1\n",
    "            [0.725000, 0.285000],  # W2\n",
    "            [0.515000, 0.515000],  # W3\n",
    "            [0.750000, 0.750000],  # W4\n",
    "            [0.990000, 0.010000],  # W5\n",
    "            [0.000029, 0.001417],  # W6\n",
    "            [0.305976, 0.997403],  # W7\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            -3.353165630322361e-61,\n",
    "            6.743225602289377e-78,\n",
    "            4.714509345171323e-13,\n",
    "            1.3319145509281447e-22,\n",
    "            0.0,\n",
    "            1.825040909472812e-247,\n",
    "            -1.5662072753465034e-167,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F2\": {\n",
    "        \"X\": np.array([\n",
    "            [0.755000, 0.275000],  # W1\n",
    "            [0.785000, 0.305000],  # W2\n",
    "            [0.740000, 0.260000],  # W3\n",
    "            [0.730000, 0.270000],  # W4\n",
    "            [0.718763, 0.261649],  # W5\n",
    "            [0.722018, 0.263976],  # W6\n",
    "            [0.721323, 0.261711],  # W7\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            0.42044085041824825,\n",
    "            -0.0456643112924181,\n",
    "            0.46274019045813003,\n",
    "            0.6060955609811236,\n",
    "            0.5195146975906033,\n",
    "            0.5794253005452772,\n",
    "            0.5796694237276565,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F3\": {\n",
    "        \"X\": np.array([\n",
    "            [0.395000, 0.875000, 0.635000],  # W1\n",
    "            [0.145000, 0.395000, 0.915000],  # W2\n",
    "            [0.120000, 0.347000, 0.943000],  # W3\n",
    "            [0.155000, 0.385000, 0.905000],  # W4\n",
    "            [0.165000, 0.375000, 0.895000],  # W5\n",
    "            [0.178771, 0.372140, 0.880781],  # W6\n",
    "            [0.184441, 0.353663, 0.875638],  # W7\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            -0.12080733985523133,\n",
    "            -0.11535196594300248,\n",
    "            -0.20076336857175398,\n",
    "            -0.07852077254038155,\n",
    "            -0.06033571734237718,\n",
    "            -0.04739292498526722,\n",
    "            -0.05056402944032541,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F4\": {\n",
    "        \"X\": np.array([\n",
    "            [0.275000, 0.955000, 0.515000, 0.145000],  # W1\n",
    "            [0.815000, 0.245000, 0.355000, 0.695000],  # W2\n",
    "            [0.869000, 0.174000, 0.339000, 0.750000],  # W3\n",
    "            [0.795000, 0.265000, 0.365000, 0.665000],  # W4\n",
    "            [0.785000, 0.275000, 0.370000, 0.650000],  # W5 (best)\n",
    "            [0.792676, 0.264502, 0.367988, 0.657198],  # W6\n",
    "            [0.791656, 0.265832, 0.368297, 0.656143],  # W7\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            -18.59723490448631,\n",
    "            -14.395540985679897,\n",
    "            -18.67377341401988,\n",
    "            -13.169944884454413,\n",
    "            -12.699964227491282,\n",
    "            -12.987699814058924,\n",
    "            -12.94099410856025,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F5\": {\n",
    "        \"X\": np.array([\n",
    "            [0.635000, 0.395000, 0.755000, 0.875000],  # W1\n",
    "            [0.665000, 0.365000, 0.785000, 0.845000],  # W2\n",
    "            [0.680000, 0.350000, 0.800000, 0.830000],  # W3\n",
    "            [0.695000, 0.335000, 0.815000, 0.815000],  # W4\n",
    "            [0.707000, 0.323000, 0.827000, 0.803000],  # W5\n",
    "            [0.728000, 0.302000, 0.848000, 0.782000],  # W6 (best)\n",
    "            [0.591139, 0.057257, 0.976087, 0.523586],  # W7 (bad global jump)\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            287.4343816627659,\n",
    "            292.2593658119571,\n",
    "            301.5311905557768,\n",
    "            315.65049985154724,\n",
    "            330.66611638919255,\n",
    "            365.66328225833024,\n",
    "            283.75880106841055,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F6\": {\n",
    "        \"X\": np.array([\n",
    "            [0.515000, 0.145000, 0.955000, 0.395000, 0.755000],  # W1\n",
    "            [0.185000, 0.745000, 0.315000, 0.865000, 0.455000],  # W2\n",
    "            [0.152000, 0.805000, 0.251000, 0.912000, 0.425000],  # W3\n",
    "            [0.170000, 0.760000, 0.300000, 0.890000, 0.470000],  # W4\n",
    "            [0.200000, 0.730000, 0.330000, 0.840000, 0.455000],  # W5\n",
    "            [0.218000, 0.712000, 0.348000, 0.810000, 0.446000],  # W6\n",
    "            [0.228800, 0.701200, 0.358800, 0.792000, 0.440600],  # W7 (best)\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            -1.6304531811460896,\n",
    "            -1.4347679755670883,\n",
    "            -1.6451191179236977,\n",
    "            -1.6022183821509282,\n",
    "            -1.3295280103104827,\n",
    "            -1.2429202946292475,\n",
    "            -1.2012624047628697,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F7\": {\n",
    "        \"X\": np.array([\n",
    "            [0.875000, 0.275000, 0.635000, 0.515000, 0.145000, 0.955000],  # W1\n",
    "            [0.845000, 0.305000, 0.665000, 0.485000, 0.175000, 0.925000],  # W2\n",
    "            [0.830000, 0.320000, 0.680000, 0.470000, 0.190000, 0.910000],  # W3\n",
    "            [0.815000, 0.335000, 0.695000, 0.455000, 0.205000, 0.895000],  # W4\n",
    "            [0.805202, 0.344798, 0.704798, 0.445202, 0.214798, 0.885202],  # W5\n",
    "            [0.791730, 0.358270, 0.718270, 0.431730, 0.228270, 0.871730],  # W6 (best)\n",
    "            [0.013373, 0.928169, 0.299072, 0.839656, 0.777563, 0.029987],  # W7 (bad global jump)\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            0.6267064847700778,\n",
    "            0.8069621926499697,\n",
    "            0.8919314248129555,\n",
    "            0.969339703275594,\n",
    "            1.0144420450032012,\n",
    "            1.0679017392374972,\n",
    "            0.10868500160826922,\n",
    "        ], float),\n",
    "    },\n",
    "\n",
    "    \"F8\": {\n",
    "        \"X\": np.array([\n",
    "            [0.145000, 0.275000, 0.395000, 0.515000, 0.635000, 0.755000, 0.875000, 0.955000],  # W1\n",
    "            [0.175000, 0.305000, 0.425000, 0.545000, 0.665000, 0.785000, 0.905000, 0.945000],  # W2\n",
    "            [0.130000, 0.260000, 0.380000, 0.500000, 0.620000, 0.740000, 0.860000, 0.960000],  # W3\n",
    "            [0.140000, 0.270000, 0.390000, 0.500000, 0.620000, 0.740000, 0.860000, 0.960000],  # W4\n",
    "            [0.120000, 0.250000, 0.370000, 0.500000, 0.620000, 0.740000, 0.860000, 0.960000],  # W5\n",
    "            [0.114226, 0.244226, 0.364226, 0.500000, 0.620000, 0.740000, 0.860000, 0.960000],  # W6\n",
    "            [0.109607, 0.239607, 0.359607, 0.500000, 0.620000, 0.740000, 0.860000, 0.960000],  # W7 (best)\n",
    "        ], float),\n",
    "        \"y\": np.array([\n",
    "            8.633935,\n",
    "            8.451335,\n",
    "            8.71814,\n",
    "            8.69914,\n",
    "            8.73594,\n",
    "            8.745671245544,\n",
    "            8.753167873306,\n",
    "        ], float),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Formatting + utility helpers\n",
    "# ============================================================\n",
    "def clip_01(x):\n",
    "    \"\"\"Clip to [0, 0.999999] so portal always shows values starting with '0.'\"\"\"\n",
    "    return np.clip(np.asarray(x, float), 0.0, 0.999999)\n",
    "\n",
    "def format_query(x):\n",
    "    \"\"\"Portal query string: 6 decimals, hyphen-separated.\"\"\"\n",
    "    return \"-\".join(f\"{v:.6f}\" for v in np.asarray(x, float))\n",
    "\n",
    "def min_dist_to_existing(x, X_existing):\n",
    "    X_existing = np.asarray(X_existing, float)\n",
    "    d = np.sqrt(((X_existing - x)**2).sum(axis=1))\n",
    "    return float(d.min())\n",
    "\n",
    "def ensure_unique_after_rounding(x, X_existing, seed=0, tries=200, jitter=1e-5):\n",
    "    \"\"\"\n",
    "    Because the portal rounds to 6 decimals, two different floats can become identical strings.\n",
    "    This nudges x slightly if needed to avoid an accidental duplicate submission.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    existing_str = {format_query(row) for row in np.asarray(X_existing, float)}\n",
    "    x = np.asarray(x, float).copy()\n",
    "\n",
    "    for _ in range(tries):\n",
    "        if format_query(x) not in existing_str:\n",
    "            return clip_01(x)\n",
    "        x = x + rng.normal(0.0, jitter, size=x.shape)\n",
    "        x = clip_01(x)\n",
    "\n",
    "    # If we somehow still collide, just return the last try (very unlikely)\n",
    "    return clip_01(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) F1 (minimal): cheap space-filling (small maximin sample)\n",
    "# ============================================================\n",
    "def propose_F1_minimal(X_existing, n_rand=8000, seed=8):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    d = X_existing.shape[1]\n",
    "    R = rng.random((n_rand, d)) * 0.999999\n",
    "    dists = np.sqrt(((R[:, None, :] - X_existing[None, :, :]) ** 2).sum(axis=2))\n",
    "    min_d = dists.min(axis=1)\n",
    "    x = R[int(np.argmax(min_d))]\n",
    "    return ensure_unique_after_rounding(x, X_existing, seed=seed+100)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) F6 (manual): continue last improving direction (damped)\n",
    "# ============================================================\n",
    "def propose_F6_continue_direction(X, y, gamma=0.60):\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "    x_prev, x_last = X[-2].copy(), X[-1].copy()\n",
    "    y_prev, y_last = float(y[-2]), float(y[-1])\n",
    "    delta = x_last - x_prev\n",
    "    x_new = x_last + gamma * delta if y_last >= y_prev else x_last - gamma * delta\n",
    "    return ensure_unique_after_rounding(clip_01(x_new), X, seed=606)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Ridge (F2,F3,F4,F8): LOOCV alpha + local step tuning\n",
    "# ============================================================\n",
    "ALPHAS = [1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "\n",
    "# Smaller steps now because we are close to good regions.\n",
    "STEP_GRID = {\n",
    "    \"F2\": [0.002, 0.004, 0.006, 0.008],\n",
    "    \"F3\": [0.006, 0.010, 0.014, 0.018],\n",
    "    \"F4\": [0.003, 0.005, 0.007, 0.009],\n",
    "    \"F8\": [0.002, 0.004, 0.006, 0.008],\n",
    "}\n",
    "\n",
    "# For F8, only adjust first 3 dimensions (others stay fixed at your current successful template).\n",
    "MASK = {\"F8\": [0, 1, 2]}\n",
    "\n",
    "def ridge_fit(X, y, alpha):\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "    if not SKLEARN_RIDGE_AVAILABLE:\n",
    "        # Closed-form ridge with intercept unregularised\n",
    "        n, d = X.shape\n",
    "        Z = np.hstack([np.ones((n, 1)), X])\n",
    "        I = np.eye(d + 1); I[0, 0] = 0.0\n",
    "        beta = np.linalg.solve(Z.T @ Z + alpha * I, Z.T @ y)\n",
    "        return float(beta[0]), beta[1:].astype(float)\n",
    "\n",
    "    model = Ridge(alpha=alpha, fit_intercept=True)\n",
    "    model.fit(X, y)\n",
    "    return float(model.intercept_), model.coef_.astype(float)\n",
    "\n",
    "def ridge_predict(b0, b, X):\n",
    "    return b0 + np.asarray(X, float) @ np.asarray(b, float)\n",
    "\n",
    "def choose_alpha_loocv(X, y, alphas):\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "    n = X.shape[0]\n",
    "    best_a, best_mse = None, np.inf\n",
    "    for a in alphas:\n",
    "        errs = []\n",
    "        for i in range(n):\n",
    "            m = np.ones(n, dtype=bool); m[i] = False\n",
    "            b0, b = ridge_fit(X[m], y[m], alpha=a)\n",
    "            yhat = ridge_predict(b0, b, X[~m])[0]\n",
    "            errs.append((y[~m][0] - yhat) ** 2)\n",
    "        mse = float(np.mean(errs))\n",
    "        if mse < best_mse:\n",
    "            best_mse, best_a = mse, a\n",
    "    return best_a, best_mse\n",
    "\n",
    "def apply_mask(v, mask):\n",
    "    v = np.asarray(v, float)\n",
    "    if mask is None:\n",
    "        return v\n",
    "    out = np.zeros_like(v)\n",
    "    out[mask] = v[mask]\n",
    "    return out\n",
    "\n",
    "def ridge_candidates(x_best, b, step, mask=None):\n",
    "    \"\"\"\n",
    "    Generate a small candidate set around x_best:\n",
    "      - move along +b direction\n",
    "      - coordinate nudges using sign(b_j)\n",
    "    \"\"\"\n",
    "    x_best = np.asarray(x_best, float)\n",
    "    b_eff = apply_mask(b, mask)\n",
    "    norm = np.linalg.norm(b_eff)\n",
    "\n",
    "    cands = []\n",
    "    if norm < 1e-12:\n",
    "        # If model is flat, do coordinate perturbations only.\n",
    "        for j in range(x_best.size):\n",
    "            if mask is not None and j not in mask:\n",
    "                continue\n",
    "            for s in [step, 0.5 * step]:\n",
    "                x1 = x_best.copy(); x1[j] += s; cands.append(x1)\n",
    "                x2 = x_best.copy(); x2[j] -= s; cands.append(x2)\n",
    "        return [clip_01(c) for c in cands]\n",
    "\n",
    "    direction = b_eff / norm\n",
    "\n",
    "    # Small and moderate move along direction (pure local exploitation)\n",
    "    for m in [0.5, 1.0]:\n",
    "        cands.append(x_best + (m * step) * direction)\n",
    "\n",
    "    # Coordinate-wise \"safe\" refinements\n",
    "    for j in range(x_best.size):\n",
    "        if mask is not None and j not in mask:\n",
    "            continue\n",
    "        sgn = np.sign(b_eff[j])\n",
    "        if sgn == 0:\n",
    "            continue\n",
    "        xj = x_best.copy()\n",
    "        xj[j] += 0.8 * step * sgn\n",
    "        cands.append(xj)\n",
    "\n",
    "    return [clip_01(c) for c in cands]\n",
    "\n",
    "def propose_ridge_next(fname, X, y):\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "\n",
    "    # Anchor at best observed point (max y)\n",
    "    best_idx = int(np.argmax(y))\n",
    "    x_best = X[best_idx].copy()\n",
    "    y_best = float(y[best_idx])\n",
    "\n",
    "    # Standardise y for numerical stability\n",
    "    y_mean, y_std = float(np.mean(y)), float(np.std(y))\n",
    "    if y_std < 1e-12:\n",
    "        y_std = 1.0\n",
    "    y_z = (y - y_mean) / y_std\n",
    "\n",
    "    # Tune alpha via LOOCV\n",
    "    alpha, loocv_mse = choose_alpha_loocv(X, y_z, ALPHAS)\n",
    "\n",
    "    # Fit ridge on all data\n",
    "    b0, b = ridge_fit(X, y_z, alpha=alpha)\n",
    "\n",
    "    mask = MASK.get(fname, None)\n",
    "\n",
    "    # Tune step by scoring candidates with predicted y_z (maximise)\n",
    "    best_score = -np.inf\n",
    "    best_step = None\n",
    "    best_x = None\n",
    "\n",
    "    for step in STEP_GRID[fname]:\n",
    "        cands = ridge_candidates(x_best, b, step, mask=mask)\n",
    "        preds = ridge_predict(b0, b, np.array(cands))\n",
    "        idx = int(np.argmax(preds))\n",
    "        if float(preds[idx]) > best_score:\n",
    "            best_score = float(preds[idx])\n",
    "            best_step = step\n",
    "            best_x = cands[idx]\n",
    "\n",
    "    best_x = ensure_unique_after_rounding(best_x, X, seed=hash(fname) % 10000)\n",
    "\n",
    "    return {\n",
    "        \"x_next\": best_x,\n",
    "        \"alpha\": alpha,\n",
    "        \"loocv_mse\": loocv_mse,\n",
    "        \"step\": best_step,\n",
    "        \"x_best\": x_best,\n",
    "        \"y_best\": y_best,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Trust-region BO (F5,F7): LOCAL-ONLY GP + EI\n",
    "#    Key differences vs your Week 7 run:\n",
    "#      - NO global candidate set\n",
    "#      - very small local_sigma\n",
    "#      - hard trust-region radius (max coordinate deviation <= 3*sigma)\n",
    "# ============================================================\n",
    "def stdnorm_pdf(z):\n",
    "    return np.exp(-0.5 * z * z) / math.sqrt(2.0 * math.pi)\n",
    "\n",
    "def stdnorm_cdf(z):\n",
    "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "\n",
    "def expected_improvement(mu, sigma, y_best, xi=1e-6):\n",
    "    \"\"\"\n",
    "    EI for maximisation (vectorised).\n",
    "    Smaller xi => more exploitation.\n",
    "    \"\"\"\n",
    "    mu = np.asarray(mu, float)\n",
    "    sigma = np.asarray(sigma, float)\n",
    "\n",
    "    ei = np.zeros_like(mu)\n",
    "    m = sigma > 1e-12\n",
    "    imp = mu[m] - y_best - xi\n",
    "    Z = imp / sigma[m]\n",
    "\n",
    "    Phi = np.array([stdnorm_cdf(z) for z in Z])\n",
    "    phi = np.array([stdnorm_pdf(z) for z in Z])\n",
    "\n",
    "    ei[m] = imp * Phi + sigma[m] * phi\n",
    "    ei[ei < 0] = 0.0\n",
    "    return ei\n",
    "\n",
    "def fit_gp(X, y, seed=0):\n",
    "    if not SKLEARN_GP_AVAILABLE:\n",
    "        raise ImportError(\"GaussianProcessRegressor not available. Install scikit-learn to use BO.\")\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "    d = X.shape[1]\n",
    "\n",
    "    # Kernel: Constant * Matern + white noise\n",
    "    kernel = (\n",
    "        C(1.0, (1e-3, 1e3)) *\n",
    "        Matern(length_scale=np.ones(d), length_scale_bounds=(1e-2, 1e2), nu=2.5)\n",
    "        + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-10, 1e-2))\n",
    "    )\n",
    "\n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=6,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    gp.fit(X, y)\n",
    "    return gp\n",
    "\n",
    "def propose_bo_trust_region(fname, X, y, seed=0, xi=1e-6, n_local=50000, local_sigma=0.006, radius_mult=3.0):\n",
    "    \"\"\"\n",
    "    Trust-region BO (LOCAL ONLY):\n",
    "      1) Fit GP on all (X,y)\n",
    "      2) Generate ONLY local candidates around best observed point\n",
    "      3) Enforce hard trust-region: max |x_i - x_best_i| <= radius_mult*local_sigma\n",
    "      4) Select argmax EI\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float); y = np.asarray(y, float)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    best_idx = int(np.argmax(y))\n",
    "    x_best = X[best_idx].copy()\n",
    "    y_best = float(y[best_idx])\n",
    "\n",
    "    gp = fit_gp(X, y, seed=seed)\n",
    "\n",
    "    d = X.shape[1]\n",
    "    radius = radius_mult * local_sigma\n",
    "\n",
    "    # LOCAL samples only\n",
    "    CANDS = x_best + rng.normal(0.0, local_sigma, size=(n_local, d))\n",
    "    CANDS = clip_01(CANDS)\n",
    "\n",
    "    # Hard trust-region filter (prevents tail events causing big jumps)\n",
    "    diff = np.abs(CANDS - x_best[None, :])\n",
    "    CANDS = CANDS[(diff <= radius).all(axis=1)]\n",
    "\n",
    "    if CANDS.shape[0] == 0:\n",
    "        # fallback if filter removed everything (rare)\n",
    "        CANDS = clip_01(x_best + rng.normal(0.0, local_sigma, size=(n_local, d)))\n",
    "\n",
    "    # Avoid exact repeats (distance check in float space; rounding uniqueness handled later)\n",
    "    keep = []\n",
    "    for i in range(CANDS.shape[0]):\n",
    "        keep.append(min_dist_to_existing(CANDS[i], X) > 1e-6)\n",
    "    CANDS = CANDS[np.array(keep, dtype=bool)]\n",
    "    if CANDS.shape[0] == 0:\n",
    "        CANDS = clip_01(x_best + rng.normal(0.0, local_sigma, size=(n_local, d)))\n",
    "\n",
    "    mu, sigma = gp.predict(CANDS, return_std=True)\n",
    "    ei = expected_improvement(mu, sigma, y_best=y_best, xi=xi)\n",
    "\n",
    "    idx = int(np.argmax(ei))\n",
    "    x_next = ensure_unique_after_rounding(CANDS[idx], X, seed=seed+999)\n",
    "\n",
    "    return {\n",
    "        \"x_next\": x_next,\n",
    "        \"x_best\": x_best,\n",
    "        \"y_best\": y_best,\n",
    "        \"kernel_\": str(gp.kernel_),\n",
    "        \"xi\": xi,\n",
    "        \"local_sigma\": local_sigma,\n",
    "        \"radius\": radius,\n",
    "        \"best_ei\": float(ei[idx]),\n",
    "        \"n_candidates\": int(CANDS.shape[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) BUILD WEEK 8 PLAN (as per your mapping)\n",
    "# ============================================================\n",
    "PLAN = {}\n",
    "\n",
    "# âš« F1: minimal\n",
    "PLAN[\"F1\"] = (\"MINIMAL_MAXIMIN\", {\"x_next\": propose_F1_minimal(DATA[\"F1\"][\"X\"], n_rand=8000, seed=8)})\n",
    "\n",
    "# ðŸŸ¡ Ridge: F2,F3,F4,F8\n",
    "for f in [\"F2\", \"F3\", \"F4\", \"F8\"]:\n",
    "    PLAN[f] = (\"RIDGE_LOCAL_TUNED\", propose_ridge_next(f, DATA[f][\"X\"], DATA[f][\"y\"]))\n",
    "\n",
    "# ðŸŸ¢ Trust-region BO: F5,F7 (LOCAL ONLY; no global candidates)\n",
    "PLAN[\"F5\"] = (\"TRUST_REGION_BO_GP_EI\", propose_bo_trust_region(\n",
    "    \"F5\", DATA[\"F5\"][\"X\"], DATA[\"F5\"][\"y\"],\n",
    "    seed=105, xi=1e-6, n_local=50000, local_sigma=0.006, radius_mult=3.0\n",
    "))\n",
    "PLAN[\"F7\"] = (\"TRUST_REGION_BO_GP_EI\", propose_bo_trust_region(\n",
    "    \"F7\", DATA[\"F7\"][\"X\"], DATA[\"F7\"][\"y\"],\n",
    "    seed=107, xi=1e-6, n_local=60000, local_sigma=0.005, radius_mult=3.0\n",
    "))\n",
    "\n",
    "# ðŸ”µ Manual: F6\n",
    "PLAN[\"F6\"] = (\"MANUAL_CONTINUE_DIR\", {\"x_next\": propose_F6_continue_direction(\n",
    "    DATA[\"F6\"][\"X\"], DATA[\"F6\"][\"y\"], gamma=0.60\n",
    ")})\n",
    "\n",
    "# ============================================================\n",
    "# 8) PRINT WEEK 8 QUERIES FOR PORTAL (F1..F8)\n",
    "# ============================================================\n",
    "print(\"==== WEEK 8 QUERIES (COPY/PASTE INTO PORTAL) ====\\n\")\n",
    "\n",
    "for f in [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"F6\", \"F7\", \"F8\"]:\n",
    "    method, info = PLAN[f]\n",
    "    x_next = info[\"x_next\"]\n",
    "\n",
    "    print(f\"{f}  [{method}]\")\n",
    "    print(f\"  Week 8 query: {format_query(x_next)}\")\n",
    "\n",
    "    # Print details (useful for your Week 8 reflection)\n",
    "    if method == \"RIDGE_LOCAL_TUNED\":\n",
    "        print(f\"  tuned alpha: {info['alpha']} | LOOCV MSE: {info['loocv_mse']:.6f} | tuned step: {info['step']}\")\n",
    "        print(f\"  best observed y: {info['y_best']:.6f} at x_best={format_query(info['x_best'])}\")\n",
    "\n",
    "    if method == \"TRUST_REGION_BO_GP_EI\":\n",
    "        print(f\"  GP kernel: {info['kernel_']}\")\n",
    "        print(f\"  EI xi: {info['xi']} | local_sigma: {info['local_sigma']} | radius: {info['radius']}\")\n",
    "        print(f\"  candidates kept: {info['n_candidates']} | best EI: {info['best_ei']:.6e}\")\n",
    "        print(f\"  best observed y: {info['y_best']:.6f} at x_best={format_query(info['x_best'])}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"Done. Paste each Week 8 query string into its function field.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9f683-9897-40f5-842c-039800808f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
